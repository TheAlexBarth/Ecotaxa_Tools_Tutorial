[
  {
    "objectID": "export_UVP_ecopart-export.html",
    "href": "export_UVP_ecopart-export.html",
    "title": "Exporting Ecopart Data",
    "section": "",
    "text": "You can always export ecopart data directly from Ecotaxa. This is how you would do it for zooscan, planktoscope, etc. However, the UVP requires access to the particle datafiles as well to calculate volume sampled in 1m bins. Exporting through ecopart will export all the files from a given project in one convenient directory."
  },
  {
    "objectID": "export_UVP_ecopart-export.html#accessing-data-on-ecopart",
    "href": "export_UVP_ecopart-export.html#accessing-data-on-ecopart",
    "title": "Exporting Ecopart Data",
    "section": "Accessing data on Ecopart:",
    "text": "Accessing data on Ecopart:\n\nGo to the ecopart website.\nSelect your project or set filters to a desired range of casts\n\nOnce projects are selected, select “export selection.\nThen Select “RAW”\n\nThis will put all the files in a .zip\nExtract those files and put them in a directory that you have access to.\n\n\n  \n    \n      Importing Data from Ecopart"
  },
  {
    "objectID": "import_UVP_ecopart_import.html",
    "href": "import_UVP_ecopart_import.html",
    "title": "Importing UVP Data From Ecopart Export",
    "section": "",
    "text": "The first step to importing ecopart data is to guarantee that you exported the data correctly from ecopart. Follow those instructions here.\nThe next step is to import your into R for analysis.\nThe exported files should all be in a single directory: \nFor this tutorial, I provided data in the package from AE1917. This is intended for examples only and not for research use. This data is stored as ecopart_example and is available throught the package\n\nImporting the data:\n\nUsing the r function ecopart_import() assign the one argument of a path to the directory of your files\nAssign the files to a list object. By using ecopart_import(), the imported files will be an ecopart_obj class structure. This class structure is defined by having three elements; (1) a par_list which has multiple par_df files; (2) a zoo_list which has multiple zoo_df files\n\n\ndir_path <- system.file('extdata','ae1917_example-data', \n                       package = 'EcotaxaTools') #This should be your directory location\necopart_list <- ecopart_import(dir_path) #load files\n\nWarning in names(par_files) != names(zoo_files): longer object length is not a\nmultiple of shorter object length\n\n\nWarning in ecopart_import(dir_path): The par_files and zoo_files don't exactly\nmatch\n\n\n\nThis will create a three element list which can be used in analysis built into EcotaxaTools. This object is an ecopart_obj class. Review the class system here\n\n“par_files” - a list of tibbles with each particle file\n“zoo_files” - a list of tibbles with each plankton image file (classic tsv)\n“meta” - a tibble with the meta\n\n\n\n\nUnderstanding the ecopart file list\nIf you are new to working with lists, it’s worth reading a bit about them. While lists can be clunky, it allows for looping over large amounts of data stored in memory.\nBelow, I’ll briefly show how to interact with some of the data stored in the ecopart list\n\nLooking at zooplankton data\nZooplankton data are stored in tibbles in the list “zoo_files”. You can access elements of a list using the $ operator or by indexing the ‘bare’ elements with [[ index operator. The names of the zoo_files correspond to the particular casts of a project.\n\n#all below with index the names files\nnames(ecopart_list$zoo_files)\n\n [1] \"bats361_ctd1\"  \"bats361_ctd2\"  \"bats361_ctd3\"  \"bats361_ctd4\" \n [5] \"bats361_ctd5\"  \"bats361_ctd6\"  \"bats361_ctd7\"  \"bats361_ctd8\" \n [9] \"bats361_ctd9\"  \"bats361_ctd12\" \"bats361_ctd13\" \"bats361_ctd14\"\n[13] \"bats361_ctd15\" \"bats361_ctd16\" \"bats361_ctd17\" \"bats361_ctd19\"\n[17] \"bats361_ctd20\" \"bats361_ctd21\" \"bats361_ctd22\" \"bats361_ctd23\"\n[21] \"bats361_ctd24\" \"bats361_ctd25\" \"bats361_ctd26\" \"bats361_ctd27\"\n\nnames(ecopart_list[[\"zoo_files\"]])\n\n [1] \"bats361_ctd1\"  \"bats361_ctd2\"  \"bats361_ctd3\"  \"bats361_ctd4\" \n [5] \"bats361_ctd5\"  \"bats361_ctd6\"  \"bats361_ctd7\"  \"bats361_ctd8\" \n [9] \"bats361_ctd9\"  \"bats361_ctd12\" \"bats361_ctd13\" \"bats361_ctd14\"\n[13] \"bats361_ctd15\" \"bats361_ctd16\" \"bats361_ctd17\" \"bats361_ctd19\"\n[17] \"bats361_ctd20\" \"bats361_ctd21\" \"bats361_ctd22\" \"bats361_ctd23\"\n[21] \"bats361_ctd24\" \"bats361_ctd25\" \"bats361_ctd26\" \"bats361_ctd27\"\n\nnames(ecopart_list[[2]])\n\n [1] \"bats361_ctd1\"  \"bats361_ctd2\"  \"bats361_ctd3\"  \"bats361_ctd4\" \n [5] \"bats361_ctd5\"  \"bats361_ctd6\"  \"bats361_ctd7\"  \"bats361_ctd8\" \n [9] \"bats361_ctd9\"  \"bats361_ctd12\" \"bats361_ctd13\" \"bats361_ctd14\"\n[13] \"bats361_ctd15\" \"bats361_ctd16\" \"bats361_ctd17\" \"bats361_ctd19\"\n[17] \"bats361_ctd20\" \"bats361_ctd21\" \"bats361_ctd22\" \"bats361_ctd23\"\n[21] \"bats361_ctd24\" \"bats361_ctd25\" \"bats361_ctd26\" \"bats361_ctd27\"\n\n\nEach zooplankton tibble has data from all vignettes collected from an individual uvp cast. You can access these in multiple ways with either the $ operator or [[ operators. These are very similar to the export data from standard Ecotaxa .tsv files. However, in an ecopart_obj, the metadata is stored separated (in the meta file). Not to worry, most EcotaxaTools functions will handle the metadata independently!\n\necopart_list$zoo_files[[3]]\n\n# A tibble: 626 × 90\n   orig_id    objid name  taxo_hierarchy classif_qual depth_including… psampleid\n   <chr>      <dbl> <chr> <chr>          <chr>                   <dbl>     <dbl>\n 1 bats361_… 1.46e8 detr… not-living>de… V                       619.      33981\n 2 bats361_… 1.46e8 Aulo… living>Eukary… V                       379.      33981\n 3 bats361_… 1.46e8 badf… not-living>ar… V                        54.1     33981\n 4 bats361_… 1.46e8 Aulo… living>Eukary… V                       420.      33981\n 5 bats361_… 1.46e8 tuff  living>Bacter… V                       104.      33981\n 6 bats361_… 1.46e8 fibe… not-living>de… V                       124.      33981\n 7 bats361_… 1.46e8 detr… not-living>de… V                       117.      33981\n 8 bats361_… 1.46e8 badf… not-living>ar… V                       115.      33981\n 9 bats361_… 1.46e8 Aula… living>Eukary… V                       543.      33981\n10 bats361_… 1.46e8 detr… not-living>de… V                       282.      33981\n# … with 616 more rows, and 83 more variables: `%area` <dbl>, angle <dbl>,\n#   area <dbl>, area_exc <dbl>, areai <dbl>, bx <dbl>, by <dbl>, cdexc <dbl>,\n#   centroids <dbl>, circ. <dbl>, circex <dbl>, compentropy <dbl>,\n#   compm1 <dbl>, compm2 <dbl>, compm3 <dbl>, compmean <dbl>, compslope <dbl>,\n#   convarea <dbl>, convarea_area <dbl>, convperim <dbl>,\n#   convperim_perim <dbl>, cv <dbl>, elongation <dbl>, esd <dbl>, fcons <dbl>,\n#   feret <dbl>, feretareaexc <dbl>, fractal <dbl>, height <dbl>, …\n\n\n\n\nLooking at particle data\nParticle data are stored in par_df tibbles for each cast. For a project, they will all be stored in the par_files element of the ecopart_obj list. Similar to the zoo_files, the names of the par_files correspond to the individual casts.\nA single par_df has 7 columns. The data here are presented in 1-m aggregate bins. Each row then is a 1-m depth bin with information about a single particle size class. Here are columns explained in detail: - The ‘depth’ column indicates the depth bin - The ‘imgcount’ column is the number of images taken in that depth bin (this is needed for volume sampled calculations) - The ‘area’ column indicates particle size as area of pixels - The ‘nbr’ column indicates the number of particles in that depth bin of that size class - The three greylimit columns correspond to the mean grey values of those particles.\n\necopart_list$par_files[[1]]\n\n# A tibble: 17,385 × 7\n   depth imgcount  area   nbr greylimit1 greylimit2 greylimit3\n   <dbl>    <dbl> <dbl> <dbl>      <dbl>      <dbl>      <dbl>\n 1     3       70    26    31          9         22         41\n 2     3       70    22    46         12         25         44\n 3     3       70    21    54         11         17         31\n 4     3       70    17    94         12         22         40\n 5     3       70    16   104         13         23         36\n 6     3       70    15   139         12         23         32\n 7     3       70    14   154         12         23         35\n 8     3       70    13   218         11         18         29\n 9     3       70    12   309         11         19         29\n10     3       70    11   375         12         19         30\n# … with 17,375 more rows"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ecotaxa Tools Guide",
    "section": "",
    "text": "The project is under current development so check back frequently. You can read the updates tab for new information here.\nThe current build is primarily for UVP and ecopart data processing. However, there is some functionality which will be useful with the zoo_scan or other standard ecotaxa .tsv files."
  },
  {
    "objectID": "info_general_ecotaxa-tsv-description.html",
    "href": "info_general_ecotaxa-tsv-description.html",
    "title": "Understanding zooplankton export files",
    "section": "",
    "text": "From ecotaxa, you export files of zooplankton data (large images). These come as .tsv files. In these files, there are a lot of data that can be a little overwhelming. However, all these columns host valuable data.\nIn general, all the columns of the .tsv file correspond to characteristics for each vignette.\nIf you export data directly from Ecotaxa, there will be metadata in the appropriate columns. For example each row has a value for the pixel to mm conversion. This is useful if you are working with Zooscan or Planktoscope data. Here, columns will be named based on what type of data are stored in it. There are ‘obj’ columns which correspond to things about the vignette. However, there are also columns related to the metadata like ‘acq’. It is a good idea to familarize yourself with what all these mean.\nHowever, if you export the data from ecopart,"
  },
  {
    "objectID": "info_updates-page.html",
    "href": "info_updates-page.html",
    "title": "Updates",
    "section": "",
    "text": "Created the quarto page to introduce the package and a short tutorial"
  },
  {
    "objectID": "info_updates-page.html#section-1",
    "href": "info_updates-page.html#section-1",
    "title": "Updates",
    "section": "4/20/22:",
    "text": "4/20/22:\n\nAdded several functions. Dedicated formatting to adders, modifiers, managers, and plotters"
  },
  {
    "objectID": "info_updates-page.html#section-2",
    "href": "info_updates-page.html#section-2",
    "title": "Updates",
    "section": "6/28/22",
    "text": "6/28/22\n\nPackage release to 1.0.0.9000 \nEcotaxaTools now uses a specific class paradigm which assigns objects a class structure. \nFrom a user perspective, this won’t be noticed largely. However, on the backend of the functions it makes things run smoothly. Now, the functions to interact with are primarily “pointers”. These direct datasets to class-specific functions. This allows for functions to function differently based input. This allows for a variety of workflows and will make scaling to include new features easier. For the time being, this might create new challenges for functions as things get worked out.\nAdded a uvp_par_conc and particle_plot features."
  },
  {
    "objectID": "info_updates-page.html#section-3",
    "href": "info_updates-page.html#section-3",
    "title": "Updates",
    "section": "8/10/22:",
    "text": "8/10/22:\n\nImproving documentation. Adding examples and example datasets"
  },
  {
    "objectID": "info_uvp_general-layout.html",
    "href": "info_uvp_general-layout.html",
    "title": "UVP General Structure",
    "section": "",
    "text": "These functions are explained below:\n\nQuerying functions:\nThere functions are to get quick information from an ecopart objects - get_all() - all_taxa()\n\n\nAdding Functions:\nThese will add a column to all zoo_df files. However, they do not remove any data from the original data.\n\n\nModifying Functions:\nThese will modify the ecopart_obj and return a new ecopart_obj. These modify the data in some new way.\n\n\nProducing Functions:\nThese functions take an ecopart_obj and will produce new data structures with summary data. These are the link to most analysis products."
  },
  {
    "objectID": "query_all-taxa.html",
    "href": "query_all-taxa.html",
    "title": "all_taxa()",
    "section": "",
    "text": "Likely, when using this function, it should be combined with unique().\n\nlibrary(EcotaxaTools)\necopart_example |>\n    all_taxa() |>\n    unique()\n\n [1] \"detritus\"                \"badfocus<artefact\"      \n [3] \"light<detritus\"          \"solitaryglobule\"        \n [5] \"tuff\"                    \"Eumalacostraca\"         \n [7] \"feces\"                   \"fiber<detritus\"         \n [9] \"Copepoda\"                \"Aulacanthidae\"          \n[11] \"puff\"                    \"Collodaria\"             \n[13] \"duplicate\"               \"Chaetognatha\"           \n[15] \"other<living\"            \"Rhizaria\"               \n[17] \"colonial<Rhizaria\"       \"Acantharea\"             \n[19] \"Aulosphaeridae\"          \"darksphere\"             \n[21] \"Ostracoda\"               \"Aulacantha\"             \n[23] \"Coelographis\"            \"Eucalanidae\"            \n[25] \"head<Chaetognatha\"       \"Castanellidae\"          \n[27] \"Coelodendridae\"          \"Actinopterygii\"         \n[29] \"Phaeodaria\"              \"temp circle\"            \n[31] \"tail<Chaetognatha\"       \"house\"                  \n[33] \"Crustacea\"               \"Foraminifera\"           \n[35] \"Medusettidae\"            \"Cnidaria<Hydrozoa\"      \n[37] \"Cnidaria<Metazoa\"        \"solitaryblack\"          \n[39] \"Pteropoda\"               \"Coelodendrum\"           \n[41] \"Ctenophora<Metazoa\"      \"colonial<Aulosphaeridae\"\n[43] \"Aulatractus\"             \"Alciopidae\"             \n[45] \"Pelagia\"                 \"artefact\"               \n[47] \"Siphonophorae\"           \"bubble\"                 \n[49] \"Poeobius\"                \"Annelida\"               \n[51] \"Cannosphaeridae\"         \"Salpida\""
  },
  {
    "objectID": "query_get-all.html",
    "href": "query_get-all.html",
    "title": "get_all()",
    "section": "",
    "text": "If you are interested in pulling just a\n\nWhat is the depth range of observations?\n\nlibrary(EcotaxaTools)\necopart_example |> \n    get_all('depth_including_offset') |>\n    range()\n\nWarning in min(x, na.rm = na.rm): no non-missing arguments to min; returning Inf\n\n\nWarning in max(x, na.rm = na.rm): no non-missing arguments to max; returning\n-Inf\n\n\n[1]  Inf -Inf\n\n\n\n\nWhat is the average size?\nWhen working with an ecopart_obj, all the size based metrics will still be in pixels, not mm. get_all() has an argument for converting pixels to mm. For this to work, you must provide an ecopart_obj, not just a zoo_list.\n\necopart_example |>\n    get_all('esd', pixel_conv = T) |>\n    mean()\n\n[1] NaN\n\n\n\n\nAdditional Info:\nWhen using, users must specify which column they are interested in querying from the zoo_df. If unfamiliar with these names you can access them by getting the column names of any single zoo_df\n\necopart_example$zoo_files$bats361_ctd1 |> \n    names()\n\n [1] \"orig_id\"                \"objid\"                  \"name\"                  \n [4] \"taxo_hierarchy\"         \"classif_qual\"           \"depth_including_offset\"\n [7] \"psampleid\"              \"%area\"                  \"angle\"                 \n[10] \"area\"                   \"area_exc\"               \"areai\"                 \n[13] \"bx\"                     \"by\"                     \"cdexc\"                 \n[16] \"centroids\"              \"circ.\"                  \"circex\"                \n[19] \"compentropy\"            \"compm1\"                 \"compm2\"                \n[22] \"compm3\"                 \"compmean\"               \"compslope\"             \n[25] \"convarea\"               \"convarea_area\"          \"convperim\"             \n[28] \"convperim_perim\"        \"cv\"                     \"elongation\"            \n[31] \"esd\"                    \"fcons\"                  \"feret\"                 \n[34] \"feretareaexc\"           \"fractal\"                \"height\"                \n[37] \"histcum1\"               \"histcum2\"               \"histcum3\"              \n[40] \"intden\"                 \"kurt\"                   \"kurt_mean\"             \n[43] \"major\"                  \"max\"                    \"mean\"                  \n[46] \"meanpos\"                \"median\"                 \"median_mean\"           \n[49] \"median_mean_range\"      \"min\"                    \"minor\"                 \n[52] \"mode\"                   \"nb1\"                    \"nb1_area\"              \n[55] \"nb1_range\"              \"nb2\"                    \"nb2_area\"              \n[58] \"nb2_range\"              \"nb3\"                    \"nb3_area\"              \n[61] \"nb3_range\"              \"perim.\"                 \"perimareaexc\"          \n[64] \"perimferet\"             \"perimmajor\"             \"range\"                 \n[67] \"skelarea\"               \"skeleton_area\"          \"skew\"                  \n[70] \"skew_mean\"              \"slope\"                  \"sr\"                    \n[73] \"stddev\"                 \"symetrieh\"              \"symetrieh_area\"        \n[76] \"symetriehc\"             \"symetriev\"              \"symetriev_area\"        \n[79] \"symetrievc\"             \"tag\"                    \"thickr\"                \n[82] \"width\"                  \"x\"                      \"xm\"                    \n[85] \"xmg5\"                   \"xstart\"                 \"y\"                     \n[88] \"ym\"                     \"ymg5\"                   \"ystart\""
  }
]